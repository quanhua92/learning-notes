{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "def maybe_download_and_extract(\n",
    "  dest_directory='data',\n",
    "  data_url='http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'):\n",
    "  \n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = dest_directory\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = data_url.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading cifar-10-binary.tar.gz 100.0%\n",
      "Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data'\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "maybe_download_and_extract(DATA_DIR, DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_data(index=0, filepath='data/cifar-10-batches-bin/data_batch_5.bin'):\n",
    "  bytestream = open(filepath, mode='rb')\n",
    "\n",
    "  label_bytes_length = 1\n",
    "  image_bytes_length = (32 ** 2) * 3\n",
    "  record_bytes_length = label_bytes_length + image_bytes_length\n",
    "\n",
    "  bytestream.seek(record_bytes_length * index, 0)\n",
    "  label_bytes = bytestream.read(label_bytes_length)\n",
    "  image_bytes = bytestream.read(image_bytes_length)\n",
    "\n",
    "  label = np.frombuffer(label_bytes, dtype=np.uint8)  \n",
    "  image = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "  \n",
    "  image = np.reshape(image, [3, 32, 32])\n",
    "  image = np.transpose(image, [1, 2, 0])\n",
    "  image = image.astype(np.float32)\n",
    "  \n",
    "  result = {\n",
    "    'image': image,\n",
    "    'label': label,\n",
    "  }\n",
    "  bytestream.close()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d15cba64e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAHlhJREFUeJztnVuMXNd1pv91Tp26943dvLRISpQUObFiOLLDaJTIcBw74yieALIHk4yNgaEHTxgEMTAGMg+CA8QOMA/OYGzDDwMP6JESZeDxZWIbVhLFsaDJQAgwI4tWZN1oRxQvMu9k89LNvlR1Va15qJJDUfvf3c0mqynv/wOILu5V+5x99jnrnKr911rL3B1CiPTINnoAQoiNQc4vRKLI+YVIFDm/EIki5xciUeT8QiSKnF+IRJHzC5Eocn4hEqW0ns5mdh+ALwDIAfx3d/9M7P21SsVHm42grVwUtF+n1w22ezfcDgCd5XZkJMYtxm098mtIq5Rpn6xcieyLmqJYZPwZMWWxnUV+5ZmxDfaN1FQu5cH27hI/L7MXLlCbRfYVO7Y8D/fLItuLXQOxU2ZZ+JgBoFTw66DnvWB7XuJj7JJrf+bcRczNL6zqyrpq5zezHMB/BfAvARwF8LSZPeruL7E+o80G/t1vvC9ou2nnTrqvC3MXg+1LF8/TPmdOHKO22CmsVvlJWmgvB9vLt95C+9Ru3UVt5cjF4s5vbEXOT1utCNuqxAkAIIvcRKs1fmMrRWzTmzYF22dfOUL7fPcbf0VttXqV2qoV/uAYG2+G+1T59mLzW8RueM0xapuc5tdImzyoRiZqtM8cuVH+yRf+jPa5kvV87L8bwAF3P+jubQBfBXD/OrYnhBgi63H+7QB+fNn/jw7ahBBvAtbj/KHPzm/48mhme8xsn5ntW1xqrWN3QohryXqc/yiAy7+o7wBw/Mo3ufted9/t7rtrke/TQojhsh7nfxrAHWZ2q5mVAXwYwKPXZlhCiOvNVa/2u3vHzD4O4O/Ql/oedvcX432AdocYM75i62SYpXKd9qk1J6itVIqs5kYkx4VzM9TGuEqFLSo3xdKv9IgxJkPFpDK2PQBotfjXuLNnw3PlvbCsBQDjN23hO4tQKvNz1q2EP23Wp6Zon9FmWCEAgPEmX4Gv10eorTrG99cjykMRUTEqzbACVkQkxStZl87v7o8BeGw92xBCbAz6hZ8QiSLnFyJR5PxCJIqcX4hEkfMLkSjrWu1fO04jmGp1LqHMXAgH8GRFLJqO27oRja1e5eOoEQmoROQkAKhEbMbjaZDlfIyecbms3QvLb0UkUKiccxlwuRsJCHIuRbWz8KXVnNhM+/zSu36F2qzLZcWc7AsA+vFngT6RaMubb+FBZuUuj0qcvzhHbcvtJWrLquF5LAouHU5MhmXuvMTPyRv2u+p3CiF+qpDzC5Eocn4hEkXOL0SiyPmFSJShrvZneYbmWHiVsuN8FXVySzhIpxYJfJjezoNEWP4zIJ4rrnomrASc54vlyCIr6bE7bwYWAQVk7UVqy0ngzFiFB6sU4OrBUoefl3qZH9sEOTdFJIioPM4DteZn+Wp5QfIFAkCjHj7uvMZX0ssVPg6/xFWH5YUFaluM5C5skguhOcKDgfJGOBdmHgnguhI9+YVIFDm/EIki5xciUeT8QiSKnF+IRJHzC5EoQ5X6iqLA9PZtQdvYeCT/WTMsvZQilXe6rXB1HQCo1Xi1lgYpJwYAF2dng+0HZs7RPjOdSPSO8Xtv3uNSX+k8L2vlrbAkNnP0x8F2ALg0G84HBwAzM7wq0kgkGGtiJDyPBakoBAC1aiTAiBwXABRlfs5q9XAVnVvvfDvtk0fy+y1HzmejzK+rpTkuA7ZnwwFBlZsiZdlIKa+1lIDTk1+IRJHzC5Eocn4hEkXOL0SiyPmFSBQ5vxCJsi6pz8wOA5gD0AXQcffdK/SAkV1mOY/QW14Oy17tRS7n9VpcKuvQmmFAHokQ23LTdLB9ZMcO2ufw6bPUNnOBS4Tnj7+h5ulPuHjoILWdPRnu113m0WjlnD8DKgWfj1LOI9U6Fpbmyg0uD1YrXLJrRiI4LXLtsDyPlvEcibnz66odiQhFJCK0REpyAcDYlvB1VY6UBusRTW8tUt+10Pl/zd35FS6EuCHRx34hEmW9zu8Avmtm3zezPddiQEKI4bDej/33uvtxM9sC4HEz+6G7P3n5GwY3hT0AMDE2us7dCSGuFet68rv78cHf0wC+BeDuwHv2uvtud9/dqPP0SEKI4XLVzm9mDTMbee01gPcDeOFaDUwIcX1Zz8f+rQC+ZX1toQTgf7r7d1bsRRSWdpvLKyUjw+xxuebU6dPUNjYZjvQCgLEpbuuRklcTozwicXzsZ6jtRy/xe+WBAweo7fgPn6e2Ig9rPeMjPIFnpeD60EiDl7UaH+XbLJNyWNVIRGWTJNsEgHotIgOO8mStXg9/1Syq/Lh6kYSmHZIgFQC6pBQdAOSR/YGUG/NI1KexxLBr0Pqu2vnd/SCAX7ja/kKIjUVSnxCJIucXIlHk/EIkipxfiESR8wuRKENN4OnuaC+HJb2FSJ2zkXJYSusS6Q0AxqY2UdvUVp6gsRpJ4GlEXbk4c4r2mYvUmDv60kvUNnPwELUhUj+v0QjPVaW4usi9IhLxV5T45dOoh+exXueyaKXGfwRWifSrjXB5tkOSalqJRwJ2I8/ESpPLkfloJAIyImW3SNSqEQkQADwSQbha9OQXIlHk/EIkipxfiESR8wuRKHJ+IRJl6Kv9nQ7Ln8eDdDKysllu8JX5sZvGqa3a4MElRZVPSakSXs09M3OG9nnme89S28EX9lPbmUhg0uQkXxUvkZx1RcEDS/KIEmBkewDQZfIHgIV2+HwutOb5viLKyPgENcGqfLW/qIbnqhxRKkoVnjuvKPO5zyOlyLLIan+XHHbHuU8ULG/hGgJ79OQXIlHk/EIkipxfiESR8wuRKHJ+IRJFzi9EogxV6suyDFVStqgeyexbqYRlqjoJHgGAakQGLEflPG4rl4ktInkdi5TrOjU3R21j28IlnABgfIxLlfVaeK7GIvn2Rkf4XFUiueeyjMuAC5fC0lany6WoWqSklZViOfciz7AsfG48IollERmwHJE+lzpczutkfH89Iuktd3hOwEojLPUZJPUJIVZAzi9Eosj5hUgUOb8QiSLnFyJR5PxCJMqKUp+ZPQzgtwCcdve3Ddo2AfgagF0ADgP4HXc/v9K28jzHyEQ4AqseyZ1XroQloBIpCQUAWcFztBURuYbKeQBarVaw/dCrx2ifxSUexXbbW26jtnqFj7EeicKr1cMRabHyVFNbeLmraomPw4zPcU7kz1EiRQKAs/A2AO3l8NwDwOg4j+CskDJlPVbuCkCVRAICgEVk3cVFnlux3uBhiSxadGScRyu22+HoWB4H+EZW8+T/cwD3XdH2IIAn3P0OAE8M/i+EeBOxovO7+5MAzl3RfD+ARwavHwHwwWs8LiHEdeZqv/NvdfcTADD4yz83CiFuSK77gp+Z7TGzfWa2b26ef/8VQgyXq3X+U2Y2DQCDvzTnlLvvdffd7r57JPJ7eyHEcLla538UwAOD1w8A+Pa1GY4QYlisRur7CoD3AJgys6MAPgXgMwC+bmYfA/AqgN9ezc4sy1BthmWUaiSqj0UClspchspLXJKJxT2dPnaS2g4ceiXYfuHcleuh/8ztN2+ntlqTl6BCiUe4xW7ZRS0s9XWMdzqX8X1VPSKZ5ly2qxI5cuECT0xaZDwqLotExV06fZzaKrPhMTaavJzb1i27qK0dmcdGk5eBiyVQrdTCxxY5ZJw6FT7mDimHF2JF53f3jxDT+1a9FyHEDYd+4SdEosj5hUgUOb8QiSLnFyJR5PxCJMpwE3iaoUyi7YpIFF5OIrBKJX7vai0tUNuRY0ep7fDBA9Q2f+lCsD0znmgxFmfVavFj3jTFE3h2IzXhQKSochab30hC05zPcSUitTbIOVtuRX7o1eHnLLNYLUe+yRKJPKxU+DhiSUZj+hu7TlfohuX2pWD7wjyPEpyYCEvjecQn3jCmVb9TCPFThZxfiESR8wuRKHJ+IRJFzi9Eosj5hUiUoUp9lhkKIg/FZBIjddXm52Zpn0OHuGR37MdHqG1pgSccKbJw0kRDJBotUvdtuRWxLfNklkWdJ6zMiaSXRe7z5txWkOSSAFCvcttELSylFSSqEwDmzvOIv9h8lCIycZ1EOU5u3kb7dCNz1V7k4xiLJJTttLiMab2wbbnF99XphK/FXjfcHkJPfiESRc4vRKLI+YVIFDm/EIki5xciUYa62u/u8F44CKZH2gHg7NmzwfaDh35E+ywtzVFbrcpXh0cjZZVYXrpIBapoYIyXwivRAFA0I8E2PJ4GyMLzmEWCdyzjq/blMrdVjAeeVPPwIKuNcPksAKiN3ExtsQApdk0BQImoLUUkk3Srw4+riCgcve4itS3Oc2Vq01h4LIvz4YAfgOeN7BIVIISe/EIkipxfiESR8wuRKHJ+IRJFzi9Eosj5hUiU1ZTrehjAbwE47e5vG7R9GsDvAjgzeNsn3f2x9Qzk+HFecunlA+EgnXMzJ2ifEgnCAYB6ROoz71Iby49WjclhOZeoyhWuEeaz56mtFCmTVdTDslF1hJcGyyu8XFepzXXFuQUuX7XLJHfe2CTtU23wgKVGRCIcGeelt1huyG4k7WKRc2MeySW4tMTno17n11yJlGbr9Xjiv4LovRYpJ3Ylq3nnnwO4L9D+eXe/a/BvXY4vhBg+Kzq/uz8JgFeiFEK8KVnPd/6Pm9lzZvawmfGfxQkhbkiu1vm/COB2AHcBOAHgs+yNZrbHzPaZ2b7ZOf5zRSHEcLkq53f3U+7edfcegC8BuDvy3r3uvtvdd4+O8EUbIcRwuSrnN7PLy8l8CMAL12Y4QohhsRqp7ysA3gNgysyOAvgUgPeY2V3oh1odBvB7q9mZu6PVbgVtf/Odv6X9DpGce0WXR19tavBD2zQZiSyr8X4NEr7nkRxyvTLfXjcio5XLPELMqjwPXoZw3rdl5znkSk0+H+VRLs2VaxGJkMiiJXAJttzjx1wGj4CsFHweK5XwXLWXed7Fos6l1FiOR8/5fJRrfI69TPIdVrk82/CwDJhFIjSvZEXnd/ePBJofWvUehBA3JPqFnxCJIucXIlHk/EIkipxfiESR8wuRKENN4Lnc6eL0TDha7dnnX6T9Fog8+Mt33Un73L5jK7WNjHFJplrjUkmNyHbVSHLMaiRyr1zhEhWLRuvbIv1IObQyibIDgGaTS0qdLo8su3iRR7H5cljS63T5rzzPnpuhttkGT8g6NjlNbbmFz00JPHqzRMrDAUA1EgG5HOlXFLyfkVJ1tUiSUV8OS7eRIbwBPfmFSBQ5vxCJIucXIlHk/EIkipxfiESR8wuRKEOV+trLbRw+eixoO3vuAu23eeuWYPv0jl20T2MTl68mJseobYTUTQOA2fNhKarc4DLOzbt2UVtRiiQSjUg2ZSINAUBOorq6nUgUG6lnBwCPPfrX1PbM95+htk2bwsmddu26hfY5N3uR2kpNnqSzNr6N2n72Z98WbO9G6vHFau6VIjJrlvHknq023+byXPi424uRCEKaaJaP4Ur05BciUeT8QiSKnF+IRJHzC5Eocn4hEmWoq/3ec7Ra4RxztUjgyXg9nIet1+Nllc7P8pXSnvHV8pmLvN+Rg+GyYW+5fQftMz4ZVioAwMCX9GOBOHWSSxAAvBNeVfZlHsgyd4ErLc88/T1qm430q1fCl9bxV1+lfXoFvxy3bt5ObYtL4WsKADrd8HEvLfAAo+PHDlLbLbfeTm1W4udlsRW5HhfDQTrdZa5IeC98XD3Xar8QYgXk/EIkipxfiESR8wuRKHJ+IRJFzi9EoqymXNdOAH8BYBuAHoC97v4FM9sE4GsAdqFfsut33D2coG9AnhnG6mEJ673v+hd8DETRq5Yi+fYi+c9qNW6bn+eSTLcbHkgpEmiTZfz+2iPbA4BOj5e16mT8tF26FA4SmWjwclFHj3L5rV+LNczUZl7Ka3Q0HFjVbPK537KdS6Z33ftuatt5+x3UxqTl1hI/zyePHqK2qSkeYFQZ4balpUiwEMnH511+DXS7RNKLnK8rWc2TvwPgD939rQDuAfAHZnYngAcBPOHudwB4YvB/IcSbhBWd391PuPszg9dzAPYD2A7gfgCPDN72CIAPXq9BCiGuPWv6zm9muwC8A8BTALa6+wmgf4MAwH/KJoS44Vi185tZE8A3AHzC3XnC9jf222Nm+8xs38Ii/94jhBguq3J+MyvQd/wvu/s3B82nzGx6YJ8GcDrU1933uvtud99dr/Ea60KI4bKi85uZAXgIwH53/9xlpkcBPDB4/QCAb1/74Qkhrherieq7F8BHATxvZs8O2j4J4DMAvm5mHwPwKoDfXmlDvV4XiyQvWSUS0TU5NhpsX1oKSyR9eM46o/nPEE2BNjkaji6ciOT9qxX8/ppXeeReFsmrtxDJ7XZ2JvgBDNNTXJb7ube+hdp2bOdLOZVI5GGjGZYWm7ESVKVIGbLmZmpbWOBfJ3sW3mYs+C02xk6Hy28WiS7skZJzANAhNha5BwDdXvgAfA1RfSs6v7v/A0BjT9+36j0JIW4o9As/IRJFzi9Eosj5hUgUOb8QiSLnFyJRhprAs1Kt4S0/9/NB25HyEdpvtBkuh9XpRkouLZ6jtnKN3/NKlbCcBwDbN4fHUc759k5GIuZiNbmclN0CgFaLS5wT4+EyWaVYgtRIpNr4ZHh7ANAjyTGBfmm2EKcv8JJcF+b4cW2e5vOxdccUtXXz8Dmbn+cBqHOXuHQ4O8flvMmcR07mbS49s+jOXkTqoxGhSuAphFgJOb8QiSLnFyJR5PxCJIqcX4hEkfMLkShDlfqyzFCvh6Os7rn3V2i/RZKEsajxKLDy/HFqO3fyJLXNZ2PUVpTD+6vWuWQ3UuMSW6kcqbmX836VgktA1Wp4m0cjx3zy5ClqK+Vc+gS4/FYiUYl5JOnqli03U9vOm3+G2opaOFkoAMyRSLt2m8t5589zGXD6Zp4gMy7NcamvSxJ1xmpRMpl19UKfnvxCJIucX4hEkfMLkShyfiESRc4vRKIMdbW/0+ngzOnwynJe8BVbK0getioPpPB5vu75xHe+S23/72UeeFIdC+fB27YpHDwCAP/qfb9Mbfe8i5eg6pZ4puNawVfML12aC/dpcmXhtjt2Ulte8HE4ze4GOMkxVyFqBABs37aN2iplrjr0jD/DatXwSnqlzMd+03Y+jpERfs11e3xFv1/pLgzLuxdd7WcBPArsEUKshJxfiESR8wuRKHJ+IRJFzi9Eosj5hUiUFaU+M9sJ4C8AbENfr9jr7l8ws08D+F0AZwZv/aS7PxbbVqfbxcz5cKmpiS1cohgfCcs8ZlzyqlS5dFiu89JVi60Zajv1ajgf3+F/4kEiOya4RPWLu7kM2C5zSWm5zYN+YOF8fKVKTDbitmXneRJh/JzVGmGJcGozL7tVqvBArV6PS3MWeYYZ6VfO+aVfigQfeaTUm0fDargty8Ljj0l9xvI/RvJCXslqdP4OgD9092fMbATA983s8YHt8+7+X1a9NyHEDcNqavWdAHBi8HrOzPYD2H69ByaEuL6s6Tu/me0C8A4ATw2aPm5mz5nZw2bGczwLIW44Vu38ZtYE8A0An3D3WQBfBHA7gLvQ/2TwWdJvj5ntM7N9iws857kQYrisyvnNrEDf8b/s7t8EAHc/5e5dd+8B+BKAu0N93X2vu+929921Ov8NvBBiuKzo/NZfVnwIwH53/9xl7dOXve1DAF649sMTQlwvVrPafy+AjwJ43syeHbR9EsBHzOwu9DWMwwB+b6UNzc8v4f8+/WLQ9urRWdrvvve/N9i+uc7LNE1uuYXa/u2//31qe/e/DkfFAcDshQvB9gtnz9I+20f5/bVZ4xFzrYhU2YtIbO1WK9heRHICZpFyY5nxKLxSHpHfiHxVlLmM1vVwBB4AeETqK0Wi+tAL7y+Sbg/VGj/mvMT3tbwYnnsA8E6ktByR9GJSH1UO1xDVt5rV/n8AgrGbUU1fCHFjo1/4CZEocn4hEkXOL0SiyPmFSBQ5vxCJMtQEnkutFn74ypGg7fCrJ2i/2fmw/Pbrv/artM8vvv2t1DYxzUtyTe7gklI5C8tGuXEZrejxiD/PeL9quUFtHeM61aX5sK1W5bJivc5tsQukTcqoAcDhI+HzXIkkH63X+TGDSIcA0AWfjw6xVRqjtM/mLTuordeNJOJc5vPhHS4DdmkuzrUU31o7evILkShyfiESRc4vRKLI+YVIFDm/EIki5xciUYYq9ZllKFittpxLQP/40v5g+8nT52ifH758gNru/qWfp7bbbuPRgPVKOBlnKRLp1cl5DoNSJIlkFoncy4nkCACVcnh/eSSqL5YAM5aks1Ti499+UzjTWz0SyZhFErLG6gJ2elxG6yEcTVdtcFmxEjmfZ0+Ek7j2B8Ij97zD6/h1SR0/i0QrMhkwnkT09ejJL0SiyPmFSBQ5vxCJIucXIlHk/EIkipxfiEQZqtQHRCSKSARTUYRlqrPnL9I+j//vJ6nNci67bNkaqSVn4emKVkdzLl8hUvcti/WLSFFFFh5NTuQkAOhGJKrYsVnEWquEJcdYVFw3FhUXmateJPEnSFTfUpvLgwsXz1Nbu83HaLGEmxEJznvEJywSQcj8ZQ2RgHryC5Eocn4hEkXOL0SiyPmFSBQ5vxCJsuJqv5lVATwJoDJ4/1+6+6fM7FYAXwWwCcAzAD7q7nzZ+J+3t+ZBspXNLOPDz0t8P5NTk9RmzldY20uXgu3e5UEzseCXWGBPHgl0QqxMFgkG8UgOvNgp6SKmVvCVZVZqqhtZEc8jq9u9Lr+0OldhW17iuRU7i5G8i5E6X73ItRNbg2fXd7fL98X8aC1Z/1bz5G8BeK+7/wL65bjvM7N7APwpgM+7+x0AzgP42Br2K4TYYFZ0fu/z2iOvGPxzAO8F8JeD9kcAfPC6jFAIcV1Y1Xd+M8sHFXpPA3gcwCsALrj/5NcVRwGEA7iFEDckq3J+d++6+10AdgC4G0AoKX7w64aZ7TGzfWa2rxeriyyEGCprWu139wsA/g+AewCMm/3k9647ABwnffa6+253351FMtAIIYbLis5vZpvNbHzwugbg1wHsB/D3AP7N4G0PAPj29RqkEOLas5rAnmkAj5hZjv7N4uvu/tdm9hKAr5rZfwLwjwAeuo7jDNKLSCH1Js8VNxGxoRUuDQYAvV452L5M2gHAu3yKezm/98akviwm2xHb1UisQDywJxaMReWryFe/PCJUxaS+5UhAUIcELXmXBwN5j9ti4/eIjBmTAZlkGptfJqWuJbBnRed39+cAvCPQfhD97/9CiDch+oWfEIki5xciUeT8QiSKnF+IRJHzC5EoFpMTrvnOzM4AODL47xSAs0PbOUfjeD0ax+t5s43jFnfniSgvY6jO/7odm+1z990bsnONQ+PQOPSxX4hUkfMLkSgb6fx7N3Dfl6NxvB6N4/X81I5jw77zCyE2Fn3sFyJRNsT5zew+M/uRmR0wswc3YgyDcRw2s+fN7Fkz2zfE/T5sZqfN7IXL2jaZ2eNm9vLg78QGjePTZnZsMCfPmtkHhjCOnWb292a238xeNLP/MGgf6pxExjHUOTGzqpl9z8x+MBjHnwzabzWzpwbz8TUz4+Gkq8Hdh/oPQI5+GrDbAJQB/ADAncMex2AshwFMbcB+3w3gnQBeuKztPwN4cPD6QQB/ukHj+DSA/zjk+ZgG8M7B6xEA/wTgzmHPSWQcQ50T9COpm4PXBYCn0E+g83UAHx60/zcAv7+e/WzEk/9uAAfc/aD3U31/FcD9GzCODcPdnwRw7orm+9FPhAoMKSEqGcfQcfcT7v7M4PUc+slitmPIcxIZx1DxPtc9ae5GOP92AD++7P8bmfzTAXzXzL5vZns2aAyvsdXdTwD9ixDAlg0cy8fN7LnB14Lr/vXjcsxsF/r5I57CBs7JFeMAhjwnw0iauxHOH0oOs1GSw73u/k4AvwngD8zs3Rs0jhuJLwK4Hf0aDScAfHZYOzazJoBvAPiEu88Oa7+rGMfQ58TXkTR3tWyE8x8FsPOy/9Pkn9cbdz8++HsawLewsZmJTpnZNAAM/p7eiEG4+6nBhdcD8CUMaU7MrEDf4b7s7t8cNA99TkLj2Kg5Gex7zUlzV8tGOP/TAO4YrFyWAXwYwKPDHoSZNcxs5LXXAN4P4IV4r+vKo+gnQgU2MCHqa8424EMYwpxYP8HgQwD2u/vnLjMNdU7YOIY9J0NLmjusFcwrVjM/gP5K6isA/miDxnAb+krDDwC8OMxxAPgK+h8fl9H/JPQxAJMAngDw8uDvpg0ax/8A8DyA59B3vukhjONd6H+EfQ7As4N/Hxj2nETGMdQ5AfB29JPiPof+jeaPL7tmvwfgAID/BaCynv3oF35CJIp+4SdEosj5hUgUOb8QiSLnFyJR5PxCJIqcX4hEkfMLkShyfiES5f8DnjkutRXuATYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d15cb52d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "result = extract_data(np.random.randint(1000))\n",
    "plt.imshow(result['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.python.feature_column import feature_column\n",
    "\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn import make_export_strategy\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_files = ['data/cifar-10-batches-bin/data_batch_{}.bin'.format(i) for i in range(1,5)]\n",
    "valid_data_files = ['data/cifar-10-batches-bin/data_batch_5.bin']\n",
    "test_data_files = ['data/cifar-10-batches-bin/test_batch.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# If a model is trained with multiple GPUs, prefix all Op names with tower_name\n",
    "# to differentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "# We use a weight decay of 0.0002, which performs better than the 0.0001 that\n",
    "# was originally suggested.\n",
    "WEIGHT_DECAY = 2e-4\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "# Global constants describing model behaviors\n",
    "MODEL_NAME = 'cnn-model-01'\n",
    "USE_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(raw_record):\n",
    "    # Every record consists of a label followed by the image, with a fixed number\n",
    "    # of bytes for each.\n",
    "    label_bytes = 1\n",
    "    image_bytes = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_vector = tf.decode_raw(raw_record, tf.uint8)\n",
    "\n",
    "    # The first byte represents the label, which we convert from uint8 to int32\n",
    "    # and then to one-hot.\n",
    "    label = tf.cast(record_vector[0], tf.int32)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "    record_vector[label_bytes:record_bytes], [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "\n",
    "    # Convert from [depth, height, width] to [height, width, depth], and cast as\n",
    "    # float32.\n",
    "    image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, is_training=False):\n",
    "    \"\"\"Preprocess a single image of layout [height, width, depth].\"\"\"\n",
    "    if is_training:\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(\n",
    "        image, IMAGE_HEIGHT + 8, IMAGE_WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_fn(file_names,\n",
    "                      mode=tf.estimator.ModeKeys.EVAL,\n",
    "                      batch_size=1):\n",
    "\n",
    "    def _input_fn():\n",
    "        label_bytes = 1\n",
    "        image_bytes = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH\n",
    "        record_bytes = label_bytes + image_bytes\n",
    "        dataset = tf.data.FixedLengthRecordDataset(filenames=file_names,\n",
    "                                                   record_bytes=record_bytes)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        if is_training:\n",
    "            buffer_size = batch_size * 2 + 1\n",
    "            dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "        dataset = dataset.map(parse_record)\n",
    "        dataset = dataset.map(lambda image, label: (preprocess_image(image, is_training), label))\n",
    "\n",
    "        dataset = dataset.prefetch(2 * batch_size)\n",
    "\n",
    "        # We call repeat after shuffling, rather than before, to prevent separate\n",
    "        # epochs from blending together.\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "        # Batch results by up to batch_size, and then fetch the tuple from the\n",
    "        # iterator.\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        images, labels = iterator.get_next()\n",
    "\n",
    "        features = {'images': images}\n",
    "        return features, labels\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns():\n",
    "    feature_columns = {\n",
    "    'images': tf.feature_column.numeric_column('images', (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH)),\n",
    "    }\n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: {'images': _NumericColumn(key='images', shape=(32, 32, 3), default_value=None, dtype=tf.float32, normalizer_fn=None)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_columns = get_feature_columns()\n",
    "print(\"Feature Columns: {}\".format(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _activation_summary(x):\n",
    "    \"\"\"Helper to create summaries for activations.\n",
    "    Creates a summary that provides a histogram of activations.\n",
    "    Creates a summary that measures the sparsity of activations.\n",
    "    Args:\n",
    "    x: Tensor\n",
    "    Returns:\n",
    "    nothing\n",
    "    \"\"\"\n",
    "    # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "    # session. This helps the clarity of presentation on tensorboard.\n",
    "    tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "    tf.summary.histogram(tensor_name + '/activations', x)\n",
    "    tf.summary.scalar(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "        dtype = tf.float32\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "    return var\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "    Note that the Variable is initialized with a truncated normal distribution.\n",
    "    A weight decay is added only if one is specified.\n",
    "    Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "    Returns:\n",
    "    Variable Tensor\n",
    "    \"\"\"\n",
    "    dtype = tf.float32\n",
    "    var = _variable_on_cpu(\n",
    "      name,\n",
    "      shape,\n",
    "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64], stddev=5e-2, wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv1)\n",
    "    \n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64], stddev=5e-2, wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        _activation_summary(conv2)\n",
    "\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "    \n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        pool2_shape = pool2.get_shape()\n",
    "        dim = pool2_shape[1] * pool2_shape[2] * pool2_shape[3]\n",
    "        reshape = tf.reshape(pool2, [-1, dim])\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 384], stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "        _activation_summary(local3)\n",
    "\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[384, 192], stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "        _activation_summary(local4)\n",
    "\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES], stddev=1/192.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES], tf.constant_initializer(0.0))\n",
    "        logits = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "        _activation_summary(logits)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loss(logits, labels):\n",
    "    # Calculate loss, which includes softmax cross entropy and L2 regularization.\n",
    "    cross_entropy = tf.losses.softmax_cross_entropy(\n",
    "    logits=logits, onehot_labels=labels)\n",
    "\n",
    "    # Create a tensor named cross_entropy for logging purposes.\n",
    "    tf.identity(cross_entropy, name='cross_entropy')\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "    # Add weight decay to the loss.\n",
    "    loss = cross_entropy + WEIGHT_DECAY * tf.add_n(\n",
    "      [tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_op(loss, params, mode):\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # Scale the learning rate linearly with the batch size. When the batch size\n",
    "        # is 128, the learning rate should be 0.1.\n",
    "        initial_learning_rate = 0.1 * params.batch_size / 128\n",
    "        batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / params.batch_size\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        # Multiply the learning rate by 0.1 at 100, 150, and 200 epochs.\n",
    "        boundaries = [int(batches_per_epoch * epoch) for epoch in [100, 150, 200]]\n",
    "        values = [initial_learning_rate * decay for decay in [1, 0.1, 0.01, 0.001]]\n",
    "        learning_rate = tf.train.piecewise_constant(\n",
    "            tf.cast(global_step, tf.int32), boundaries, values)\n",
    "\n",
    "        # Create a tensor named learning_rate for logging purposes\n",
    "        tf.identity(learning_rate, name='learning_rate')\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "        optimizer = tf.train.MomentumOptimizer(\n",
    "            learning_rate=learning_rate,\n",
    "            momentum=MOMENTUM)\n",
    "\n",
    "        # Batch norm requires update ops to be added as a dependency to the train_op\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss, global_step)\n",
    "    else:\n",
    "        train_op = None\n",
    "\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(predictions, labels):\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.metrics.accuracy(predictions['classes'],\n",
    "                                 tf.argmax(labels, axis=1))\n",
    "\n",
    "    # Create a tensor named train_accuracy for logging purposes\n",
    "    tf.identity(accuracy[1], name='train_accuracy')\n",
    "    tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "\n",
    "    return {'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    # Create the input layers from the features\n",
    "    feature_columns = list(get_feature_columns().values())\n",
    "\n",
    "    images = tf.feature_column.input_layer(\n",
    "    features=features, feature_columns=feature_columns)\n",
    "\n",
    "    images = tf.reshape(\n",
    "    images, shape=(-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH))\n",
    "\n",
    "    # Calculate logits through CNN\n",
    "    logits = inference(images)\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = {\n",
    "    'classes': tf.argmax(logits, axis=1),\n",
    "    'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "\n",
    "    # Provide an estimator spec for `ModeKeys.PREDICT`\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        export_outputs = {\n",
    "          'predictions': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      predictions=predictions,\n",
    "                                      export_outputs=export_outputs)\n",
    "\n",
    "    loss = get_loss(logits=logits, labels=labels)\n",
    "    train_op = get_train_op(loss=loss, mode=mode, params=params)\n",
    "    metrics = get_metrics(predictions=predictions, labels=labels)\n",
    "\n",
    "    # Return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "    mode=mode,\n",
    "    predictions=predictions,\n",
    "    loss=loss,\n",
    "    train_op=train_op,\n",
    "    eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(run_config, hparams):\n",
    "    return tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      params=hparams,\n",
    "      config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = tf.contrib.training.HParams(\n",
    "  batch_size=200,\n",
    "  max_steps=100000,\n",
    ")\n",
    "\n",
    "model_dir = 'trained_models/{}'.format(MODEL_NAME)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "  save_checkpoints_steps=100,\n",
    "  tf_random_seed=19851211,\n",
    "  model_dir=model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_environment': 'local', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_evaluation_master': '', '_model_dir': 'trained_models/cnn-model-01', '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_save_checkpoints_secs': None, '_tf_random_seed': 19851211, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D1633113C8>, '_master': '', '_task_type': None, '_log_step_count_steps': 100, '_is_chief': True, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "estimator = create_estimator(run_config, hparams)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "  input_fn=generate_input_fn(file_names=train_data_files,\n",
    "                             mode=tf.contrib.learn.ModeKeys.TRAIN,\n",
    "                             batch_size=hparams.batch_size),\n",
    "  max_steps=hparams.max_steps,\n",
    "  hooks=None\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "  input_fn=generate_input_fn(file_names=valid_data_files,\n",
    "                             mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "                             batch_size=hparams.batch_size),\n",
    "  steps=50,\n",
    "  name=None,\n",
    "  hooks=None,\n",
    "  start_delay_secs=120,\n",
    "  throttle_secs=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing previous artifacts...\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.53161\n",
      "INFO:tensorflow:Saving checkpoints for 101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.1991\n",
      "INFO:tensorflow:step = 101, loss = 2.82478 (7.040 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3742\n",
      "INFO:tensorflow:step = 201, loss = 2.79661 (6.963 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6083\n",
      "INFO:tensorflow:step = 301, loss = 2.76467 (6.852 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.312\n",
      "INFO:tensorflow:step = 401, loss = 2.73688 (6.976 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5971\n",
      "INFO:tensorflow:step = 501, loss = 2.71076 (6.861 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4705\n",
      "INFO:tensorflow:step = 601, loss = 2.68723 (6.909 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3045\n",
      "INFO:tensorflow:step = 701, loss = 2.66135 (6.985 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.1023\n",
      "INFO:tensorflow:step = 801, loss = 2.64175 (7.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.1442\n",
      "INFO:tensorflow:step = 901, loss = 2.61844 (7.058 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4332\n",
      "INFO:tensorflow:step = 1001, loss = 2.58876 (6.932 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 13.8316\n",
      "INFO:tensorflow:step = 1101, loss = 2.3568 (7.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.0662\n",
      "INFO:tensorflow:step = 1201, loss = 2.28892 (7.110 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3072\n",
      "INFO:tensorflow:step = 1301, loss = 2.17211 (6.996 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 13.8847\n",
      "INFO:tensorflow:step = 1401, loss = 1.96638 (7.192 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.0022\n",
      "INFO:tensorflow:step = 1501, loss = 1.97863 (7.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3219\n",
      "INFO:tensorflow:step = 1601, loss = 1.95582 (6.984 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.1039\n",
      "INFO:tensorflow:step = 1701, loss = 1.99821 (7.096 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7625\n",
      "INFO:tensorflow:step = 1801, loss = 1.91237 (6.766 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.2328\n",
      "INFO:tensorflow:step = 1901, loss = 1.81053 (7.034 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3621\n",
      "INFO:tensorflow:step = 2001, loss = 1.87312 (6.972 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4522\n",
      "INFO:tensorflow:step = 2101, loss = 1.84363 (6.906 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4663\n",
      "INFO:tensorflow:step = 2201, loss = 1.79924 (6.928 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5127\n",
      "INFO:tensorflow:step = 2301, loss = 1.93596 (6.892 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4917\n",
      "INFO:tensorflow:step = 2401, loss = 1.86604 (6.904 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.316\n",
      "INFO:tensorflow:step = 2501, loss = 1.84155 (6.969 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3726\n",
      "INFO:tensorflow:step = 2601, loss = 1.90761 (6.946 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.003\n",
      "INFO:tensorflow:step = 2701, loss = 1.84276 (7.146 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.256\n",
      "INFO:tensorflow:step = 2801, loss = 1.80655 (7.014 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7406\n",
      "INFO:tensorflow:step = 2901, loss = 1.81684 (6.788 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8816\n",
      "INFO:tensorflow:step = 3001, loss = 1.79195 (6.729 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8843\n",
      "INFO:tensorflow:step = 3101, loss = 1.86683 (6.722 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7309\n",
      "INFO:tensorflow:step = 3201, loss = 1.75879 (6.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4476\n",
      "INFO:tensorflow:step = 3301, loss = 1.76333 (6.921 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5708\n",
      "INFO:tensorflow:step = 3401, loss = 1.59036 (6.870 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8984\n",
      "INFO:tensorflow:step = 3501, loss = 1.58469 (6.701 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7351\n",
      "INFO:tensorflow:step = 3601, loss = 1.61553 (6.795 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8347\n",
      "INFO:tensorflow:step = 3701, loss = 1.84686 (6.748 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5816\n",
      "INFO:tensorflow:step = 3801, loss = 1.76227 (6.856 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6934\n",
      "INFO:tensorflow:step = 3901, loss = 1.60978 (6.812 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6957\n",
      "INFO:tensorflow:step = 4001, loss = 1.77672 (6.793 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6245\n",
      "INFO:tensorflow:step = 4101, loss = 1.85348 (6.834 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4018\n",
      "INFO:tensorflow:step = 4201, loss = 1.67691 (6.957 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9506\n",
      "INFO:tensorflow:step = 4301, loss = 1.87105 (6.688 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0598\n",
      "INFO:tensorflow:step = 4401, loss = 1.41967 (6.630 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7812\n",
      "INFO:tensorflow:step = 4501, loss = 1.85558 (6.769 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7117\n",
      "INFO:tensorflow:step = 4601, loss = 1.71622 (6.803 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9184\n",
      "INFO:tensorflow:step = 4701, loss = 1.96739 (6.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1296\n",
      "INFO:tensorflow:step = 4801, loss = 1.76862 (6.616 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6792\n",
      "INFO:tensorflow:step = 4901, loss = 1.84602 (6.805 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9994\n",
      "INFO:tensorflow:step = 5001, loss = 1.65198 (6.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.2619\n",
      "INFO:tensorflow:step = 5101, loss = 1.74725 (6.559 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7381\n",
      "INFO:tensorflow:step = 5201, loss = 1.58873 (6.784 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.854\n",
      "INFO:tensorflow:step = 5301, loss = 1.72703 (6.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.3939\n",
      "INFO:tensorflow:step = 5401, loss = 1.75776 (6.963 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0155\n",
      "INFO:tensorflow:step = 5501, loss = 1.70106 (6.655 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8145\n",
      "INFO:tensorflow:step = 5601, loss = 1.80408 (6.750 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1997\n",
      "INFO:tensorflow:step = 5701, loss = 1.81489 (6.577 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0331\n",
      "INFO:tensorflow:step = 5801, loss = 1.75184 (6.660 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7126\n",
      "INFO:tensorflow:step = 5901, loss = 1.64708 (6.790 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5081\n",
      "INFO:tensorflow:step = 6001, loss = 1.684 (6.902 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8524\n",
      "INFO:tensorflow:step = 6101, loss = 1.78829 (6.719 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6063\n",
      "INFO:tensorflow:step = 6201, loss = 1.79428 (6.843 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.3125\n",
      "INFO:tensorflow:step = 6301, loss = 1.94475 (6.556 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7103\n",
      "INFO:tensorflow:step = 6401, loss = 1.63868 (6.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8156\n",
      "INFO:tensorflow:step = 6501, loss = 1.68586 (6.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9043\n",
      "INFO:tensorflow:step = 6601, loss = 1.75704 (6.714 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7641\n",
      "INFO:tensorflow:step = 6701, loss = 1.65482 (6.776 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7445\n",
      "INFO:tensorflow:step = 6801, loss = 1.63472 (6.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.295\n",
      "INFO:tensorflow:step = 6901, loss = 1.84185 (6.536 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6586\n",
      "INFO:tensorflow:step = 7001, loss = 1.78925 (6.811 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0578\n",
      "INFO:tensorflow:step = 7101, loss = 1.80522 (6.648 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8408\n",
      "INFO:tensorflow:step = 7201, loss = 1.60579 (6.744 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8598\n",
      "INFO:tensorflow:step = 7301, loss = 1.83821 (6.733 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0143\n",
      "INFO:tensorflow:step = 7401, loss = 1.48602 (6.646 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1287\n",
      "INFO:tensorflow:step = 7501, loss = 1.84129 (6.616 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9631\n",
      "INFO:tensorflow:step = 7601, loss = 1.78427 (6.696 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7701 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.093\n",
      "INFO:tensorflow:step = 7701, loss = 1.7137 (6.620 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7801 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9189\n",
      "INFO:tensorflow:step = 7801, loss = 1.74742 (6.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7901 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0445\n",
      "INFO:tensorflow:step = 7901, loss = 1.91155 (6.641 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7601\n",
      "INFO:tensorflow:step = 8001, loss = 1.58801 (6.781 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8101 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0243\n",
      "INFO:tensorflow:step = 8101, loss = 1.75778 (6.663 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8201 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.846\n",
      "INFO:tensorflow:step = 8201, loss = 1.67166 (6.725 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8301 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.149\n",
      "INFO:tensorflow:step = 8301, loss = 1.80751 (6.598 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8401 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9058\n",
      "INFO:tensorflow:step = 8401, loss = 1.68409 (6.707 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8501 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.985\n",
      "INFO:tensorflow:step = 8501, loss = 1.73954 (6.672 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8601 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9542\n",
      "INFO:tensorflow:step = 8601, loss = 1.58851 (6.686 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8701 into trained_models/cnn-model-01\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 14.8544\n",
      "INFO:tensorflow:step = 8701, loss = 2.02931 (6.738 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8766 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.97516.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-14-15:57:50\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cnn-model-01\\model.ckpt-8766\n",
      "INFO:tensorflow:Evaluation [1/50]\n",
      "INFO:tensorflow:Evaluation [2/50]\n",
      "INFO:tensorflow:Evaluation [3/50]\n",
      "INFO:tensorflow:Evaluation [4/50]\n",
      "INFO:tensorflow:Evaluation [5/50]\n",
      "INFO:tensorflow:Evaluation [6/50]\n",
      "INFO:tensorflow:Evaluation [7/50]\n",
      "INFO:tensorflow:Evaluation [8/50]\n",
      "INFO:tensorflow:Evaluation [9/50]\n",
      "INFO:tensorflow:Evaluation [10/50]\n",
      "INFO:tensorflow:Evaluation [11/50]\n",
      "INFO:tensorflow:Evaluation [12/50]\n",
      "INFO:tensorflow:Evaluation [13/50]\n",
      "INFO:tensorflow:Evaluation [14/50]\n",
      "INFO:tensorflow:Evaluation [15/50]\n",
      "INFO:tensorflow:Evaluation [16/50]\n",
      "INFO:tensorflow:Evaluation [17/50]\n",
      "INFO:tensorflow:Evaluation [18/50]\n",
      "INFO:tensorflow:Evaluation [19/50]\n",
      "INFO:tensorflow:Evaluation [20/50]\n",
      "INFO:tensorflow:Evaluation [21/50]\n",
      "INFO:tensorflow:Evaluation [22/50]\n",
      "INFO:tensorflow:Evaluation [23/50]\n",
      "INFO:tensorflow:Evaluation [24/50]\n",
      "INFO:tensorflow:Evaluation [25/50]\n",
      "INFO:tensorflow:Evaluation [26/50]\n",
      "INFO:tensorflow:Evaluation [27/50]\n",
      "INFO:tensorflow:Evaluation [28/50]\n",
      "INFO:tensorflow:Evaluation [29/50]\n",
      "INFO:tensorflow:Evaluation [30/50]\n",
      "INFO:tensorflow:Evaluation [31/50]\n",
      "INFO:tensorflow:Evaluation [32/50]\n",
      "INFO:tensorflow:Evaluation [33/50]\n",
      "INFO:tensorflow:Evaluation [34/50]\n",
      "INFO:tensorflow:Evaluation [35/50]\n",
      "INFO:tensorflow:Evaluation [36/50]\n",
      "INFO:tensorflow:Evaluation [37/50]\n",
      "INFO:tensorflow:Evaluation [38/50]\n",
      "INFO:tensorflow:Evaluation [39/50]\n",
      "INFO:tensorflow:Evaluation [40/50]\n",
      "INFO:tensorflow:Evaluation [41/50]\n",
      "INFO:tensorflow:Evaluation [42/50]\n",
      "INFO:tensorflow:Evaluation [43/50]\n",
      "INFO:tensorflow:Evaluation [44/50]\n",
      "INFO:tensorflow:Evaluation [45/50]\n",
      "INFO:tensorflow:Evaluation [46/50]\n",
      "INFO:tensorflow:Evaluation [47/50]\n",
      "INFO:tensorflow:Evaluation [48/50]\n",
      "INFO:tensorflow:Evaluation [49/50]\n",
      "INFO:tensorflow:Evaluation [50/50]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-14-15:57:52\n",
      "INFO:tensorflow:Saving dict for global step 8766: accuracy = 0.5425, global_step = 8766, loss = 1.80442\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from trained_models/cnn-model-01\\model.ckpt-8766\n",
      "INFO:tensorflow:Saving checkpoints for 8767 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:step = 8767, loss = 1.76696\n",
      "INFO:tensorflow:Saving checkpoints for 8867 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.4806\n",
      "INFO:tensorflow:step = 8867, loss = 1.8598 (6.905 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8967 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.2296\n",
      "INFO:tensorflow:step = 8967, loss = 1.91069 (6.575 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9067 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8891\n",
      "INFO:tensorflow:step = 9067, loss = 1.75123 (6.727 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9167 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6122\n",
      "INFO:tensorflow:step = 9167, loss = 1.93798 (6.833 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9267 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9805\n",
      "INFO:tensorflow:step = 9267, loss = 1.79415 (6.663 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9367 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8585\n",
      "INFO:tensorflow:step = 9367, loss = 1.82399 (6.740 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9467 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.3087\n",
      "INFO:tensorflow:step = 9467, loss = 1.8765 (6.530 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9567 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6302\n",
      "INFO:tensorflow:step = 9567, loss = 1.6039 (6.839 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9667 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8496\n",
      "INFO:tensorflow:step = 9667, loss = 1.85231 (6.724 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9767 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7158\n",
      "INFO:tensorflow:step = 9767, loss = 1.94892 (6.815 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9867 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7278\n",
      "INFO:tensorflow:step = 9867, loss = 1.68965 (6.770 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9967 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8457\n",
      "INFO:tensorflow:step = 9967, loss = 1.57463 (6.739 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10067 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1559\n",
      "INFO:tensorflow:step = 10067, loss = 1.72472 (6.596 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10167 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9881\n",
      "INFO:tensorflow:step = 10167, loss = 1.49279 (6.675 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10267 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9514\n",
      "INFO:tensorflow:step = 10267, loss = 1.77788 (6.696 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10367 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.958\n",
      "INFO:tensorflow:step = 10367, loss = 1.66181 (6.676 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10467 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1045\n",
      "INFO:tensorflow:step = 10467, loss = 2.0792 (6.627 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10567 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9519\n",
      "INFO:tensorflow:step = 10567, loss = 1.79256 (6.676 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10667 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8844\n",
      "INFO:tensorflow:step = 10667, loss = 1.62683 (6.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10767 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7202\n",
      "INFO:tensorflow:step = 10767, loss = 1.77351 (6.803 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10867 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8309\n",
      "INFO:tensorflow:step = 10867, loss = 1.66926 (6.738 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10967 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8264\n",
      "INFO:tensorflow:step = 10967, loss = 1.81141 (6.758 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11067 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.931\n",
      "INFO:tensorflow:step = 11067, loss = 1.86212 (6.694 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11167 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9997\n",
      "INFO:tensorflow:step = 11167, loss = 1.71579 (6.667 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11267 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.2107\n",
      "INFO:tensorflow:step = 11267, loss = 1.78361 (6.567 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11367 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9045\n",
      "INFO:tensorflow:step = 11367, loss = 1.683 (6.712 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11467 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0445\n",
      "INFO:tensorflow:step = 11467, loss = 1.90662 (6.644 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11567 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6415\n",
      "INFO:tensorflow:step = 11567, loss = 1.73052 (6.827 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11667 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9536\n",
      "INFO:tensorflow:step = 11667, loss = 1.85201 (6.700 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11767 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1187\n",
      "INFO:tensorflow:step = 11767, loss = 1.84993 (6.607 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11867 into trained_models/cnn-model-01\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 14.9173\n",
      "INFO:tensorflow:step = 11867, loss = 1.71916 (6.711 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11967 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8974\n",
      "INFO:tensorflow:step = 11967, loss = 1.69115 (6.708 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12067 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7328\n",
      "INFO:tensorflow:step = 12067, loss = 1.79292 (6.777 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12167 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6244\n",
      "INFO:tensorflow:step = 12167, loss = 1.76884 (6.845 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12267 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.813\n",
      "INFO:tensorflow:step = 12267, loss = 1.77488 (6.760 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12367 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9179\n",
      "INFO:tensorflow:step = 12367, loss = 1.65124 (6.700 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12467 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8846\n",
      "INFO:tensorflow:step = 12467, loss = 1.82285 (6.722 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12567 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7066\n",
      "INFO:tensorflow:step = 12567, loss = 1.84656 (6.786 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12667 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0284\n",
      "INFO:tensorflow:step = 12667, loss = 1.60867 (6.656 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12767 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9042\n",
      "INFO:tensorflow:step = 12767, loss = 1.74793 (6.722 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12867 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6803\n",
      "INFO:tensorflow:step = 12867, loss = 1.97922 (6.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12967 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0744\n",
      "INFO:tensorflow:step = 12967, loss = 1.7471 (6.648 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13067 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0933\n",
      "INFO:tensorflow:step = 13067, loss = 1.70065 (6.610 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13167 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1635\n",
      "INFO:tensorflow:step = 13167, loss = 1.86303 (6.599 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13267 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.0944\n",
      "INFO:tensorflow:step = 13267, loss = 1.75094 (6.631 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13367 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8839\n",
      "INFO:tensorflow:step = 13367, loss = 1.65821 (6.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13467 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8152\n",
      "INFO:tensorflow:step = 13467, loss = 1.97815 (6.743 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13567 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5444\n",
      "INFO:tensorflow:step = 13567, loss = 1.6296 (6.886 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13667 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8864\n",
      "INFO:tensorflow:step = 13667, loss = 1.72704 (6.702 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13767 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.3025\n",
      "INFO:tensorflow:step = 13767, loss = 1.65031 (6.534 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13867 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 15.1096\n",
      "INFO:tensorflow:step = 13867, loss = 1.81464 (6.640 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13967 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9104\n",
      "INFO:tensorflow:step = 13967, loss = 2.08274 (6.694 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14067 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.8089\n",
      "INFO:tensorflow:step = 14067, loss = 1.91838 (6.759 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14167 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.7147\n",
      "INFO:tensorflow:step = 14167, loss = 1.71102 (6.798 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14267 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6486\n",
      "INFO:tensorflow:step = 14267, loss = 1.75191 (6.830 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14367 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9936\n",
      "INFO:tensorflow:step = 14367, loss = 1.66661 (6.666 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14467 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.9805\n",
      "INFO:tensorflow:step = 14467, loss = 1.88216 (6.681 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14567 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.2946\n",
      "INFO:tensorflow:step = 14567, loss = 1.75313 (6.976 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14667 into trained_models/cnn-model-01\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.5408\n",
      "INFO:tensorflow:step = 14667, loss = 1.69422 (6.874 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-c29ccd08c5b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    428\u001b[0m       config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    429\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m     \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m           hooks=train_hooks)\n\u001b[0m\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m       \u001b[1;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    893\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Miniconda3\\envs\\env3-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not USE_CHECKPOINT:\n",
    "    print(\"Removing previous artifacts...\")\n",
    "    shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
