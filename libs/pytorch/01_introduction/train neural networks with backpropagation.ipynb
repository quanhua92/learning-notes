{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(\"MNIST_data/\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a feed-forward network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10) # logits, instead of output of the softmax\n",
    ")\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2984, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass to get the logits\n",
    "logits = model(images)\n",
    "\n",
    "# pass the logits to criterion to get the loss\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `nn.LogSoftmax` and `nn.NLLLoss`\n",
    "It is more convinient to build model with log-softmax output instead of output from Linear and use the negative log likelihood loss.\n",
    "\n",
    "Then, you can get the actual probabilities by taking torch.exp(output) instead of taking softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a feed-forward network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1) # dim=1 to calc softmax across columns instead of rows\n",
    ")\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3229, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass to get the logits\n",
    "log_probs = model(images)\n",
    "\n",
    "# pass the logits to criterion to get the loss\n",
    "loss = criterion(log_probs, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Autograd to perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2292, -0.0670],\n",
      "        [ 0.3727,  0.7215]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5109, 0.0045],\n",
      "        [0.1389, 0.5205]], grad_fn=<PowBackward0>)\n",
      "<PowBackward0 object at 0x0000029EDAFE50F0>\n"
     ]
    }
   ],
   "source": [
    "y = x ** 2\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5437, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad:  tensor([[ 0.6146, -0.0335],\n",
      "        [ 0.1864,  0.3607]])\n",
      "x: tensor([[ 1.2292, -0.0670],\n",
      "        [ 0.3727,  0.7215]], requires_grad=True)\n",
      "x/2:  tensor([[ 0.6146, -0.0335],\n",
      "        [ 0.1864,  0.3607]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"grad: \", x.grad)\n",
    "print(\"x:\", x)\n",
    "print(\"x/2: \", x / 2) # equal to gradients mathamatically = x / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to perform backward pass and get the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        ...,\n",
      "        [-0.0035, -0.0035, -0.0035,  ..., -0.0035, -0.0035, -0.0035],\n",
      "        [-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019],\n",
      "        [-0.0001, -0.0001, -0.0001,  ..., -0.0001, -0.0001, -0.0001]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward pass: \\n\", model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"After backward pass: \\n\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "\n",
    "Use the optimizer from PyTorch `optim` package to update weights with the gradients. For example, stochastic gradient descent is `optim.SGD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and the learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the optimizer to update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process with Pytorch:\n",
    "- Make a forward pass\n",
    "- Calculate loss\n",
    "- Perform backward pass with loss.backward()\n",
    "- Take a step with optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: \n",
      " Parameter containing:\n",
      "tensor([[ 0.0081,  0.0258,  0.0300,  ...,  0.0350, -0.0177, -0.0321],\n",
      "        [-0.0066,  0.0236, -0.0282,  ...,  0.0331,  0.0227,  0.0195],\n",
      "        [-0.0145, -0.0124,  0.0335,  ...,  0.0044, -0.0012,  0.0035],\n",
      "        ...,\n",
      "        [-0.0130,  0.0051, -0.0198,  ..., -0.0084,  0.0017,  0.0072],\n",
      "        [-0.0137,  0.0196,  0.0293,  ...,  0.0093,  0.0272, -0.0152],\n",
      "        [-0.0330,  0.0202,  0.0066,  ...,  0.0088, -0.0242,  0.0046]],\n",
      "       requires_grad=True)\n",
      "Gradient: \n",
      " tensor([[-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
      "        ...,\n",
      "        [-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "        [ 0.0047,  0.0047,  0.0047,  ...,  0.0047,  0.0047,  0.0047],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004]])\n",
      "Updated weights: \n",
      " Parameter containing:\n",
      "tensor([[ 0.0081,  0.0258,  0.0300,  ...,  0.0350, -0.0177, -0.0321],\n",
      "        [-0.0066,  0.0236, -0.0282,  ...,  0.0331,  0.0227,  0.0195],\n",
      "        [-0.0144, -0.0124,  0.0336,  ...,  0.0044, -0.0012,  0.0036],\n",
      "        ...,\n",
      "        [-0.0130,  0.0052, -0.0197,  ..., -0.0084,  0.0017,  0.0072],\n",
      "        [-0.0138,  0.0195,  0.0292,  ...,  0.0092,  0.0271, -0.0153],\n",
      "        [-0.0330,  0.0202,  0.0066,  ...,  0.0088, -0.0242,  0.0046]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights: \\n\", model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(64, 784)\n",
    "\n",
    "# !Important: Clear the gradients. otherwise, the gradients will be accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "print(\"Gradient: \\n\", model[0].weight.grad)\n",
    "\n",
    "# Take a update step with the optimizer\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Updated weights: \\n\", model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.23869899142462053\n",
      "Training loss: 0.219593421109259\n",
      "Training loss: 0.20316559299906053\n",
      "Training loss: 0.1880630064906596\n",
      "Training loss: 0.1747898718298498\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # !Important: Clear the gradients. otherwise, the gradients will be accumulated\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Take a update step with the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, -1)\n",
    "\n",
    "# turn off gradients to speed up\n",
    "with torch.no_grad():\n",
    "    probs = model.forward(img)\n",
    "\n",
    "output = torch.exp(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29ee843f748>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view(1, 28, 28).squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4732439e-07 1.2705384e-06 6.6373350e-06 9.9960142e-01 2.9570666e-08\n",
      "  2.3409531e-04 4.2051900e-11 6.8191332e-07 1.4067911e-04 1.5030907e-05]]\n",
      "predict: tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(output.numpy())\n",
    "print(\"predict:\", np.argmax(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
