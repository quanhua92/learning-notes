{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(\"MNIST_data/\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2293c20e7f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "features = images.view((images.shape[0], -1))\n",
    "\n",
    "n_input = features.shape[1]\n",
    "n_hidden  = 256\n",
    "n_output = 10\n",
    "\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "B1 = torch.randn(n_hidden)\n",
    "\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "B2 = torch.randn(n_output)\n",
    "\n",
    "H1 = activation(torch.mm(features, W1) + B1)\n",
    "H2 = torch.mm(H1, W2) + B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 256]), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H1.shape, H2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = softmax(H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(out.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define transformations\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # define activations\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uses common operations in `torch.nn.functional as F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define transformations\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # pass input tensor through each of our operations\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define transformations\n",
    "        self.hidden_1 = nn.Linear(784, 128)\n",
    "        self.hidden_2 = nn.Linear(128, 64)        \n",
    "        self.output = nn.Linear(64, 10)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # pass input tensor through each of our operations\n",
    "        x = F.relu(self.hidden_1(x))\n",
    "        x = F.relu(self.hidden_2(x))\n",
    "        x = F.softmax(self.output(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden_2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
